{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Tuple, TypeVar\n",
    "import random\n",
    "from typing import Callable, Dict, List, Tuple, TypeVar\n",
    "from collections import Counter\n",
    "from util import *\n",
    "FeatureVector = Dict[str, int]\n",
    "WeightVector = Dict[str, float]\n",
    "Example = Tuple[FeatureVector, int]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 2, 'am': 2, 'what': 1}\n"
     ]
    }
   ],
   "source": [
    "def extractWordFeatures(x: str) -> FeatureVector:\n",
    "    \"\"\"\n",
    "    Extract word features for a string x. Words are delimited by\n",
    "    whitespace characters only.\n",
    "    @param string x:\n",
    "    @return dict: feature vector representation of x.\n",
    "    Example: \"I am what I am\" --> {'I': 2, 'am': 2, 'what': 1}\n",
    "    \"\"\"\n",
    "    # BEGIN_YOUR_CODE (our solution is 4 lines of code, but don't worry if you deviate from this)\n",
    "    wordList = x.split( )\n",
    "    return dict(Counter(wordList))\n",
    "\n",
    "testCase = \"train this dog\"\n",
    "testCase = \"I am what I am\"\n",
    "result = extractWordFeatures(testCase)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function util.evaluatePredictor(examples: List[Tuple[Dict[str, int], int]], predictor: Callable) -> float>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluatePredictor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the features are strings x\n",
    "the feature vector phi(x) = FeatureVector(x)\n",
    "trainExamples = list of tuples of strings and positve +1 or negative -1\n",
    "\n",
    "Implement the function learnPredictor using stochastic gradient descent and minimize hinge loss. Print the training error and validation error after each epoch to make sure your code is working. You must get less than 4% error rate on the training set and less than 30% error rate on the validation set to get full credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar('T')\n",
    "\n",
    "\n",
    "def learnPredictor(trainExamples: List[Tuple[T, int]],\n",
    "                   validationExamples: List[Tuple[T, int]],\n",
    "                   featureExtractor: Callable[[T], FeatureVector],\n",
    "                   numEpochs: int, eta: float) -> WeightVector:\n",
    "    '''\n",
    "    Given |trainExamples| and |validationExamples| (each one is a list of (x,y)\n",
    "    pairs), a |featureExtractor| to apply to x, and the number of epochs to\n",
    "    train |numEpochs|, the step size |eta|, return the weight vector (sparse\n",
    "    feature vector) learned.\n",
    "\n",
    "    You should implement stochastic gradient descent.\n",
    "\n",
    "    Notes:\n",
    "    - Only use the trainExamples for training!\n",
    "    - You should call evaluatePredictor() on both trainExamples and validationExamples\n",
    "    to see how you're doing as you learn after each epoch.\n",
    "    - The predictor should output +1 if the score is precisely 0.\n",
    "    '''\n",
    "    weights = {}  # feature => weight\n",
    "\n",
    "    # BEGIN_YOUR_CODE (our solution is 13 lines of code, but don't worry if you deviate from this)\n",
    "    def evalHingeLoss(featureVector, y, weights):\n",
    "        margin = dotProduct(weights, featureVector)*y\n",
    "        if margin < 1:\n",
    "            hingeLoss = 1 - margin\n",
    "        else:\n",
    "            hingeLoss = 0\n",
    "        return hingeLoss\n",
    "\n",
    "    def predictClass(x):\n",
    "        featureVector = featureExtractor(x)\n",
    "        score = dotProduct(weights, featureVector)\n",
    "        if score < 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    for i in range(numEpochs):\n",
    "        for item in trainExamples:\n",
    "            x, y = item\n",
    "            featureVector = featureExtractor(x)\n",
    "            hingeLoss = evalHingeLoss(featureVector, y, weights)\n",
    "            if hingeLoss > 0:\n",
    "                increment(weights, eta*y, featureVector)\n",
    "    \n",
    "    print(f'Epoch Number: {numEpochs}')\n",
    "    print(f'Training error: {evaluatePredictor(trainExamples, predictClass)}')\n",
    "    print(f'Validation error: {evaluatePredictor(validationExamples, predictClass)}')\n",
    "    # END_YOUR_CODE\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "468819c82e791b0f9a8e64a9b2ca550cabcbea14dfb8d98bf6b8daf534ac0400"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
